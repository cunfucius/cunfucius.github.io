[
  {
    "objectID": "website/projects/index.html",
    "href": "website/projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Predicting House Prices with Machine Learning\n\n\n\nPython\n\n\nMachine Learning\n\n\nData Cleaning\n\n\n\nThis project involves using machine learning algorithms to predict house prices based on various features such as location, size, and amenities. It includes data cleaning, feature engineering, and model selection.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustomer Segmentation Using Clustering Techniques\n\n\n\nR\n\n\nMachine Learning\n\n\nClustering\n\n\nStatistical Modelling\n\n\n\nThis project focuses on segmenting customers into different groups based on their purchasing behavior and demographics. It uses clustering algorithms like K-means and hierarchical clustering to identify distinct customer segments.\n\n\n\nApr 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing Global CO2 Emissions\n\n\n\nR\n\n\nData Visualization\n\n\nEnvironmental Science\n\n\n\nThis project involves creating visualizations to show trends in global CO2 emissions over time. It includes data extraction from public databases, data cleaning, and using visualization libraries to create interactive charts and graphs.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "website/index.html",
    "href": "website/index.html",
    "title": "Angelina",
    "section": "",
    "text": "A little bit about me and my life."
  },
  {
    "objectID": "website/index.html#education",
    "href": "website/index.html#education",
    "title": "Angelina",
    "section": "Education",
    "text": "Education\nUniversity of XYZ, City | Location | Sept 20XX - June 20XX"
  },
  {
    "objectID": "website/index.html#experience",
    "href": "website/index.html#experience",
    "title": "Angelina",
    "section": "Experience",
    "text": "Experience\nWorkplace | Job title | April 20XX - present"
  },
  {
    "objectID": "website/blog/second-post/index.html",
    "href": "website/blog/second-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Quis imperdiet massa tincidunt nunc pulvinar sapien et ligula. Amet cursus sit amet dictum sit amet. Eget duis at tellus at urna condimentum. Convallis aenean et tortor at risus viverra. Tincidunt ornare massa eget egestas purus viverra accumsan. Et malesuada fames ac turpis egestas. At imperdiet dui accumsan sit amet. Ut ornare lectus sit amet est placerat. Enim nulla aliquet porttitor lacus luctus accumsan tortor posuere. Duis ultricies lacus sed turpis tincidunt id aliquet risus. Mattis enim ut tellus elementum sagittis. Dui id ornare arcu odio ut. Natoque penatibus et magnis dis. Libero justo laoreet sit amet cursus sit. Sed faucibus turpis in eu. Tempus iaculis urna id volutpat lacus laoreet.\nPhasellus vestibulum lorem sed risus. Eget felis eget nunc lobortis mattis. Sit amet aliquam id diam maecenas ultricies. Egestas maecenas pharetra convallis posuere morbi. Etiam erat velit scelerisque in dictum non consectetur a erat. Cras fermentum odio eu feugiat pretium nibh ipsum consequat. Viverra accumsan in nisl nisi scelerisque. Et netus et malesuada fames ac. Amet tellus cras adipiscing enim eu turpis egestas pretium aenean. Eget lorem dolor sed viverra ipsum nunc aliquet. Ultrices dui sapien eget mi proin sed libero enim sed. Ultricies mi eget mauris pharetra et ultrices neque. Ipsum suspendisse ultrices gravida dictum. A arcu cursus vitae congue mauris rhoncus aenean vel. Gravida arcu ac tortor dignissim convallis. Nulla posuere sollicitudin aliquam ultrices."
  },
  {
    "objectID": "newtab.html",
    "href": "newtab.html",
    "title": "Math 437 Project",
    "section": "",
    "text": "This page will contain my Math 437 final project."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Angelina",
    "section": "",
    "text": "A little bit about me and my life."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Angelina",
    "section": "Education",
    "text": "Education\nUniversity of XYZ, City | Location | Sept 20XX - June 20XX"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Angelina",
    "section": "Experience",
    "text": "Experience\nWorkplace | Job title | April 20XX - present"
  },
  {
    "objectID": "website/blog/first-post/index.html",
    "href": "website/blog/first-post/index.html",
    "title": "First Post",
    "section": "",
    "text": "Sed risus ultricies tristique nulla aliquet. Neque volutpat ac tincidunt vitae semper quis lectus nulla.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Enim sed faucibus turpis in eu mi bibendum neque. Ac orci phasellus egestas tellus rutrum tellus pellentesque eu. Velit sed ullamcorper morbi tincidunt ornare massa. Sagittis id consectetur purus ut faucibus pulvinar elementum integer. Tincidunt nunc pulvinar sapien et ligula ullamcorper malesuada proin libero. Lobortis feugiat vivamus at augue eget arcu. Aliquam ut porttitor leo a diam sollicitudin tempor id eu. Mauris a diam maecenas sed enim ut sem viverra aliquet. Enim ut tellus elementum sagittis vitae et leo duis. Molestie at elementum eu facilisis sed odio morbi quis commodo. Sapien pellentesque habitant morbi tristique senectus. Quam vulputate dignissim suspendisse in est. Nulla pellentesque dignissim enim sit amet venenatis urna cursus eget.\nVelit aliquet sagittis id consectetur purus ut faucibus pulvinar elementum. Viverra mauris in aliquam sem fringilla ut morbi tincidunt augue. Tortor at auctor urna nunc id. Sit amet consectetur adipiscing elit duis tristique sollicitudin. Aliquet nibh praesent tristique magna sit amet purus. Tristique senectus et netus et malesuada fames ac turpis. Hac habitasse platea dictumst quisque. Auctor neque vitae tempus quam pellentesque nec nam aliquam. Ultrices tincidunt arcu non sodales neque sodales ut etiam. Iaculis at erat pellentesque adipiscing. Cras tincidunt lobortis feugiat vivamus. Nisi est sit amet facilisis magna etiam. Pharetra pharetra massa massa ultricies mi quis hendrerit. Vitae sapien pellentesque habitant morbi tristique senectus. Ornare aenean euismod elementum nisi quis eleifend quam adipiscing vitae."
  },
  {
    "objectID": "website/blog/third-post/index.html",
    "href": "website/blog/third-post/index.html",
    "title": "Third Blog Post",
    "section": "",
    "text": "The source for any page in your website could also be a Jupyter Notebook. This one is third-post/index.ipynb.\nHere’s an example I borrowed from the Seaborn docs:\n\nimport seaborn as sns\n\nsns.set_theme(style=\"whitegrid\")\n\n# Load the diamonds dataset\ndiamonds = sns.load_dataset(\"diamonds\")\n\n# Plot the distribution of clarity ratings, conditional on carat\nsns.displot(\n    data=diamonds,\n    x=\"carat\", hue=\"cut\",\n    kind=\"kde\", height=4, aspect=1.5,\n    multiple=\"fill\", clip=(0, None),\n    palette=\"ch:rot=-.25,hue=1,light=.75\",   \n)"
  },
  {
    "objectID": "website/newtab.html",
    "href": "website/newtab.html",
    "title": "Math 437 Project",
    "section": "",
    "text": "This page will contain my Math 437 final project."
  },
  {
    "objectID": "newtab.html#motivation-and-context",
    "href": "newtab.html#motivation-and-context",
    "title": "Math 437 Project",
    "section": "Motivation and Context",
    "text": "Motivation and Context\nI’ve always been into UFC — it’s something I grew up watching with my dad and brothers, and Saturday night fights became kind of a tradition in our house. The UFC (Ultimate Fighting Championship) is the largest professional organization in the world for mixed martial arts (MMA), where fighters compete using a combination of striking and grappling techniques from various combat sports like boxing, wrestling, Muay Thai, and Brazilian jiu-jitsu.\nOver time, I started noticing how some matchups felt more “predictable” than others, not just based on who was more hyped or popular, but based on things like reach, stamina, or how good someone’s ground game was. That’s what made me wonder: is there a way to use actual stats to predict who’s more likely to win a fight?\nThis project is a chance for me to explore that idea through data. I’m using real UFC fight stats to see if we can predict winners based on measurable differences between fighters — like who has better striking accuracy, more fight experience, or stronger takedown defense. I think it’s cool to combine something I’ve always been interested about with the skills I’ve been learning.\nBesides just being interesting to me, this kind of analysis could be useful for coaches, fighters, sports analysts, and even fans who love debating fight outcomes. Even betting markets or commentators might benefit from knowing what stats may matter when it comes to winning a fight; it overlaps with how sportsbooks and bettors think. Oddsmakers set betting lines based on a combination of stats, trends, and public perception and sharp bettors look for mismatches between the odds and what the data suggests. By building models that identify which stats actually matter, we might find undervalued fighters or better understand why certain odds are set the way they are. Even if we’re not trying to beat the bookies, it’s interesting to explore how predictive analytics aligns (or doesn’t) with betting markets.\nThat said, I also recognize that MMA is unpredictable. One well-timed punch, an unexpected submission, or even a bad judging decision can swing the outcome of a fight. No model can account for everything — and part of what makes UFC exciting is that there’s always a bit of chaos. But if we can better understand the patterns behind consistent wins and losses, I think we can at least shift the odds a little more in our favor.\nMy goal is to take all these raw stats and figure out what they’re really telling us about the chances of a fighter coming out on top."
  },
  {
    "objectID": "newtab.html#main-objective",
    "href": "newtab.html#main-objective",
    "title": "Math 437 Project",
    "section": "Main Objective",
    "text": "Main Objective\nThe main goal of this project is to build a predictive model that can estimate the probability of a fighter winning a UFC match based on measurable stats. I’m focusing on using pre-fight data — like striking accuracy, takedown defense, fight history, and physical attributes — to see how well we can predict the outcome before the fight happens.\nWhile the primary focus is on prediction, I also want to explore which factors are most important in influencing those predictions. For example, does having a longer reach actually help? Do knockdowns matter more than takedowns? Or is fight experience the biggest difference-maker? By building the model and looking at how different variables contribute to it, I hope to find out which stats are the most useful when it comes to winning a fight.\nIn the end, the goal isn’t to perfectly guess every winner — that’s not realistic in a sport with so much unpredictability. But if we can consistently identify what gives fighters the edge, we can start making more informed predictions, and maybe even better understand how UFC matchups play out."
  },
  {
    "objectID": "newtab.html#packages-used-in-this-analysis",
    "href": "newtab.html#packages-used-in-this-analysis",
    "title": "Math 437 Project",
    "section": "Packages Used In This Analysis",
    "text": "Packages Used In This Analysis\n\nlibrary(here)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(rsample)\nlibrary(naniar)\nlibrary(janitor)\nlibrary(recipes)\nlibrary(tidymodels)  # for modeling pipeline (individual parts listed below)\nlibrary(yardstick)   \nlibrary(parsnip)    \nlibrary(workflows)   \nlibrary(vip)         \n\n\n\n\nPackage\nUse\n\n\n\n\nhere\nto easily load and save data\n\n\nreadr\nto import the CSV file data\n\n\ndplyr\nto massage and summarize data\n\n\nrsample\nto split data into training and test sets\n\n\nggplot2\nto create nice-looking and informative graphs\n\n\nnaniar\nto summarize and visualize missing data\n\n\njanitor\nto clean column names and spot duplicates/inconsistencies\n\n\nrecipes\nto preprocess data (e.g., normalize, impute, encode)\n\n\nparsnip\nto define models (e.g., logistic regression, random forest)\n\n\nworkflows\nto bundle modeling and preprocessing into one object\n\n\nyardstick\nto measure model performance (accuracy, AUC, etc.)\n\n\nvip\nto generate variable importance plots\n\n\n\n\nNote: While many of these packages come from the tidyverse and tidymodels ecosystems, they’re listed individually to clarify their specific roles in the analysis, as recommended…"
  },
  {
    "objectID": "newtab.html#data-description",
    "href": "newtab.html#data-description",
    "title": "Math 437 Project",
    "section": "Data Description",
    "text": "Data Description\n\nufc &lt;- readr::read_csv(here::here(\"C:/Users/CSUFTitan/Documents/Math 437/Data/large_dataset.csv\"))\n\nThe dataset used in this analysis comes from Kaggle, where a user compiled UFC fight statistics by scraping data directly from UFCStats.com — the official statistics provider for the UFC, basically the official record book and data hub for everything UFC. The scraper was custom-built using Python and BeautifulSoup, and the full scraping code is publicly available on Kaggle, confirming that the data is pulled directly from the source. This is the kaggle dataset link: https://www.kaggle.com/datasets/maksbasher/ufc-complete-dataset-all-events-1996-2024/data and this is the link to their scraper: https://www.kaggle.com/code/maksbasher/large-dataset-scraper-all-fights\nThe dataset includes UFC fights ranging from 1996 to March 2024, based on all completed events listed on UFCStats at the time the scraper was run. This provides a wide historical view of UFC matchups and fighter performance over time. Also a note, the dataset only includes fights that have a definite winner - there are no fights within the dataset that have draws. In total, the dataset includes over 7,000 fights and 95 variables, capturing both fight-level and fighter-level information. Each row represents one fight, these include:\n\nFight-specific details like event name, weight class, method of victory, number of rounds, and time.\nFighter performance stats such as significant strikes, takedowns, submissions, and control time.\nFighter attributes including age, height, reach, stance, and overall win/loss records.\nCalculated differences between the Red and Blue fighters for various stats (e.g., reach_diff, str_acc_diff). All fighter differences are calculated as “Red Corner - Blue Corner,” allowing for direct comparisons between the two opponents. These differences include metrics such as striking accuracy difference, takedown accuracy difference, and total wins/losses difference, allowing for easy side-by-side comparison; a positive value suggests the Red fighter has a longer reach, while a negative value indicates the Blue fighter has the advantage.\nNote that measurements (height & reach) are by CM, weight is measured in KG and time is measured in seconds.\n\n\nData Limitations\nWhile the UFC dataset provides a large and detailed collection of fight statistics, there are several limitations that should be considered when interpreting any results. First, the dataset spans fights from 1996 to 2024, but the UFC has evolved significantly during that time. Changes in judging criteria, rule enforcement, and even how certain statistics are recorded mean that older fights may not be directly comparable to more recent ones. This introduces potential bias if the entire dataset is modeled as if all fights occurred under the same conditions. For greater consistency, it may be better to focus on fights from a more recent era, such as post-2015, where rules and data collection may have became more standardized.\nAnother issue involves fighter attributes like age, height, and reach. These values appear to be assigned statically, meaning a fighter’s current or initial stats are applied to all their fights. For instance, a fighter listed as 34 years old may appear that way in fights that occurred ten years earlier. This is especially problematic for age, which is known to impact endurance and performance. Ideally, age should be calculated based on the fighter’s date of birth and the actual date of the fight.\nIn addition, the dataset lacks important qualitative information that often influences fight outcomes. Factors like injuries, short-notice fights, or last-minute weight cuts aren’t captured. This means a statistically superior fighter might lose due to context-specific issues that the model can’t see. Furthermore, many fights are decided by judges, and judging can be subjective or controversial. A fighter may statistically outperform their opponent but still lose a decision, which adds noise to the “winner” label used in prediction.\nFinally, the dataset doesn’t account for career stages or fighter rankings. Fights between debuting athletes may look very different statistically from fights between top contenders, but the model treats all of them the same unless filtered by criteria like weight class or fight type. These limitations highlight the importance of interpreting model results carefully and being transparent about what the data can and cannot reveal."
  },
  {
    "objectID": "newtab.html#data-wrangling-optional-section",
    "href": "newtab.html#data-wrangling-optional-section",
    "title": "Math 437 Project",
    "section": "Data Wrangling (Optional Section)",
    "text": "Data Wrangling (Optional Section)\n\nufc_recent &lt;- ufc |&gt; slice_head(n = 4441)\n# fights from 2015 onward, decided to focus on the \"modern\" era...rules up-to-date, less missing/incomplete data. also more \"recent\"\n\n\n#Missingness summary\n#computes the percentage of missing values for each column in dataset\n#summary shows the exact number of missing values (n_miss) and the percentage of missing values (pct_miss) for each variable/column.\n\nufc_recent |&gt;\n  miss_var_summary()\n\n# A tibble: 95 × 3\n   variable   n_miss pct_miss\n   &lt;chr&gt;       &lt;int&gt;    &lt;num&gt;\n 1 reach_diff    143    3.22 \n 2 b_reach        99    2.23 \n 3 r_reach        44    0.991\n 4 referee        24    0.540\n 5 b_stance       16    0.360\n 6 r_stance        5    0.113\n 7 event_name      0    0    \n 8 r_fighter       0    0    \n 9 b_fighter       0    0    \n10 winner          0    0    \n# ℹ 85 more rows\n\nvis_miss(ufc_recent, sort_miss = TRUE)\n\n\n\n\n\n\n\ngg_miss_upset(ufc_recent, nsets = 10)\n\n\n\n\n\n\n\n\n\n ufc_recent &lt;- ufc_recent |&gt;\n  filter(!is.na(r_stance), !is.na(b_stance), !is.na(referee)) #drop rows with NA values - less than 1% missing data\n\n\n# Start clean from the full imputed data\nufc_recent &lt;- ufc_recent|&gt;\n  filter(winner %in% c(\"Red\", \"Blue\")) |&gt;\n  mutate(\n    win_red = factor(ifelse(winner == \"Red\", 1, 0), levels = c(0, 1), labels = c(\"Blue\", \"Red\")))\n\n\n#Dropping categorical missings costs almost nothing and avoids weird “Unknown” patterns.\n\n\n#Impute r_reach and b_reach using KNN , data is 1-2% missing\nimpute_recipe &lt;- recipe(win_red ~ ., data = ufc_recent) |&gt;\n  update_role(event_name, r_fighter, b_fighter, winner, new_role = \"id\") |&gt;\n  step_impute_knn(r_reach, b_reach)\n\nprep_impute &lt;- prep(impute_recipe)\nufc_imputed &lt;- bake(prep_impute, new_data = NULL)\n\nufc_imputed &lt;- ufc_imputed |&gt;\n  mutate(reach_diff = r_reach - b_reach)\n\n\n# Make sure the outcome is a factor\nufc_imputed &lt;- ufc_imputed |&gt;\n  filter(winner %in% c(\"Red\", \"Blue\")) |&gt;\n  mutate(\n    win_red = factor(ifelse(winner == \"Red\", 1, 0), levels = c(0, 1), labels = c(\"Blue\", \"Red\"))\n  )\n\n\n# Set seed for reproducibility\nset.seed(123)\nn &lt;- nrow(ufc_imputed)\ntrain_indices &lt;- sample(n, size = floor(0.8 * n))\n# Split the dataset into training and test sets\ntrain_data &lt;- ufc_imputed[train_indices, ]\ntest_data &lt;- ufc_imputed[-train_indices, ]\n\nAfter filtering for fights from 2015 onward, the dataset was found to be largely complete, with under 3.5% missingness in any individual variable. For the few variables with missing data, I used context-driven approaches. Numeric variables like r_reach and b_reach were imputed using k-nearest neighbors (KNN) to preserve the relationships between fighters’ physical stats. The reach_diff variable, which is derived from those columns, was recalculated post-imputation to ensure consistency. Low-missing categorical variables like stance and rows missing referee were dropped instead of encoding it as unknown to avoid introducing noise.\nAlso, since we are predicting the winner of a UFC fight based on fighter statistics, it is essential to split the data into a training and test set to ensure the model generalizes well to new fights. Without this split, the model could overfit, meaning it would perform well on past fights but struggle to predict future ones. By using an 80/20 split, where 80% of the data is used for training and 20% is reserved for testing, we can evaluate the model’s accuracy on unseen data and ensure it makes reliable predictions."
  },
  {
    "objectID": "newtab.html#exploratory-data-analysis",
    "href": "newtab.html#exploratory-data-analysis",
    "title": "Math 437 Project",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\n# Distribution of Fight Outcomes (Target Variable)\n\nufc_imputed |&gt;\n  ggplot(aes(x = factor(win_red))) +\n  geom_bar(fill = \"darkred\") +\n  labs(x = \"Red Fighter Won (1 = Yes)\", y = \"Number of Fights\",\n       title = \"Distribution of Fight Outcomes\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Univariate Distributions of Difference Variables\n\nufc_imputed |&gt;\n  pivot_longer(cols = c(age_diff, reach_diff, td_diff, sig_str_acc_diff, ctrl_sec_diff, sig_str_acc_total_diff),\n               names_to = \"variable\", values_to = \"value\") |&gt;\n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 30, fill = \"lightblue\", color = \"black\") +\n  facet_wrap(~ variable, scales = \"free\") +\n  theme_minimal() +\n  labs(title = \"Distributions of Key Difference Variables\")\n\n\n\n\n\n\n\n# Boxplots of Differences by Outcome\n\nufc_imputed |&gt;\n  pivot_longer(cols = c(reach_diff, sig_str_acc_diff, td_diff, age_diff, ctrl_sec_diff, sig_str_acc_total_diff),\n               names_to = \"variable\", values_to = \"value\") |&gt;\n  ggplot(aes(x = factor(win_red), y = value, fill = factor(win_red))) +\n  geom_boxplot() +\n  facet_wrap(~ variable, scales = \"free\") +\n  theme_minimal() +\n  labs(x = \"Red Win\", y = NULL, title = \"Difference Variables by Outcome\") +\n  guides(fill = \"none\")\n\n\n\n\n\n\n\n# Raw Fighter Stats (Red Corner) by Outcome\n\nufc_imputed |&gt;\n  pivot_longer(cols = c(r_sig_str_acc_total, r_td_avg, r_str_def_total),\n               names_to = \"stat\", values_to = \"value\") |&gt;\n  ggplot(aes(x = value, fill = factor(win_red))) +\n  geom_density(alpha = 0.4) +\n  facet_wrap(~ stat, scales = \"free\") +\n  labs(title = \"Red Fighter Stats by Outcome\", fill = \"Red Win\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Categorical Variable Analysis\n\nufc_imputed |&gt;\n  ggplot(aes(x = weight_class, fill = factor(win_red))) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Win Proportion by Weight Class\", y = \"Proportion\", fill = \"Red Win\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n# Exploring Nonlinearities (Age Difference)\n\nufc_imputed |&gt;\n  mutate(age_bin = cut(age_diff, breaks = c(-Inf, -5, -2, 0, 2, 5, Inf))) |&gt;\n  ggplot(aes(x = age_bin, fill = factor(win_red))) +\n  geom_bar(position = \"fill\") +\n  labs(title = \"Proportion of Wins by Age Difference Bin\", x = \"Age Difference Bin\", y = \"Proportion\") +\n  theme_minimal()\n\n\n\n\n\n\n\n#Interactions: Reach Difference and Weight Class\n\nufc_imputed |&gt;\n  ggplot(aes(x = reach_diff, fill = factor(win_red))) +\n  geom_density(alpha = 0.4) +\n  facet_wrap(~ weight_class, scales = \"free_y\") +\n  labs(title = \"Reach Difference by Outcome across Weight Classes\", x = \"Reach Difference\") +\n  theme_minimal()\n\nWarning: Groups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\nGroups with fewer than two data points have been dropped.\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\n\n\n\n\nTo begin exploring the dataset, I visualized the distribution of the target variable, win_red, which indicates whether the red corner fighter won the bout. The bar chart reveals that red fighters win more often than blue fighters in this dataset, with a modest class imbalance that should be noted when modeling.\nNext, I examined the distributions of several key “difference” variables—such as age_diff, reach_diff, td_diff, ctrl_sec_diff, sig_str_acc_diff, and sig_str_acc_total_diff. These variables represent differences between red and blue fighters and are good candidates for predictive modeling, as they encode head-to-head advantages. Most of these variables were roughly symmetric and centered around zero, as expected from paired differences. However, some (like ctrl_sec_diff) showed skewness, and others like sig_str_acc_diff included extreme values such as -1, reflecting instances where one fighter landed no significant strikes. These values likely occur in very short fights or UFC debuts and may warrant further consideration or capping in modeling; some values approached +1 or -1, which raised red flags. After investigating further, I realized this variable was calculated using in-fight statistics — meaning it reflects what happened during the fight, not before. Including it in a predictive model would introduce data leakage since we wouldn’t know these values before the fight actually occurred. So when modeling I will use sig_str_acc_total_diff instead, which captures historical striking accuracy leading into the fight, and is more appropriate for predictive modeling.\nTo explore relationships with the outcome, I used boxplots to compare the same difference variables across win/loss outcomes. Variables such as ctrl_sec_diff and td_diff showed visible shifts depending on the winner, suggesting predictive potential. Meanwhile, differences like age_diff and reach_diff appeared more subtle and might interact with other factors like weight class or require non-linear treatment.\nTo dive deeper into those possibilities, I plotted red fighter statistics (e.g., r_sig_str_acc_total, r_str_def_total, and r_td_avg) by win outcome using density plots. While the distributions are fairly overlapping, red winners tended to have slightly higher values across all three metrics, especially in defensive and grappling stats.\nCategorical variables like weight_class were also explored. A stacked bar chart showed that the likelihood of a red win varies across weight classes, with some divisions showing strong red-side trends. This suggests a potential arena for interaction effects or confounding from matchup dynamics.\nFinally, I explored non-linear patterns by binning age_diff and plotting win proportions across bins. Older red fighters (especially 5+ years older than their opponent) appear to have lower win rates, hinting at diminishing returns with age. For interaction effects, I facet-plotted reach difference distributions by weight class, colored by win outcome. Some classes (e.g., Featherweight or Middleweight) showed clearer separation between winners and losers, indicating that the predictive value of reach may be more relevant in specific divisions.\nTogether, these plots helped identify promising predictors, revealed potential non-linear or interaction effects, and raised considerations for handling edge cases in modeling. The next steps will focus on refining the feature set and fitting appropriate predictive models."
  },
  {
    "objectID": "newtab.html#modeling",
    "href": "newtab.html#modeling",
    "title": "Math 437 Project",
    "section": "Modeling",
    "text": "Modeling\n\nlibrary(tidymodels)\n\n# Set roles and select predictor variables\nlog_recipe &lt;- recipe(win_red ~ age_diff + reach_diff + td_diff + ctrl_sec_diff + sig_str_acc_total_diff,\n                     data = train_data) |&gt;\n  step_normalize(all_numeric_predictors())\n\n# Model specification\nlogistic_mod &lt;- logistic_reg() |&gt;\n  set_engine(\"glm\") |&gt;\n  set_mode(\"classification\")\n\n# Workflow\nlogistic_wf &lt;- workflow() |&gt;\n  add_recipe(log_recipe) |&gt;\n  add_model(logistic_mod)\n\n# Fit model\nlogistic_fit &lt;- fit(logistic_wf, data = train_data)\n\n# Predictions on test set\nlog_predictions &lt;- predict(logistic_fit, new_data = test_data, type = \"prob\") |&gt;\n  bind_cols(predict(logistic_fit, new_data = test_data)) |&gt;\n  bind_cols(test_data |&gt; select(win_red))\n\n# Evaluate\nlog_predictions |&gt; metrics(truth = win_red, estimate = .pred_class)\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.689\n2 kap      binary         0.356\n\n# ROC AUC\nlog_predictions |&gt; roc_auc(truth = win_red, .pred_Red)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.237\n\n# Confusion matrix\nlog_predictions |&gt; conf_mat(truth = win_red, estimate = .pred_class)\n\n          Truth\nPrediction Blue Red\n      Blue  217 105\n      Red   169 389\n\n\n\n# Random Forest model spec\nrf_mod &lt;- rand_forest(mtry = 3, trees = 500, min_n = 5) |&gt;\n  set_engine(\"ranger\", importance = \"impurity\") |&gt;\n  set_mode(\"classification\")\n\n# Same preprocessing recipe as before\nrf_recipe &lt;- recipe(win_red ~ age_diff + reach_diff + td_diff + ctrl_sec_diff + sig_str_acc_total_diff,\n                    data = train_data) |&gt;\n  step_normalize(all_numeric_predictors())\n\n# Workflow\nrf_wf &lt;- workflow() |&gt;\n  add_recipe(rf_recipe) |&gt;\n  add_model(rf_mod)\n\n# Fit the random forest model\nrf_fit &lt;- fit(rf_wf, data = train_data)\n\n# Predictions\nrf_preds &lt;- predict(rf_fit, new_data = test_data, type = \"prob\") |&gt;\n  bind_cols(predict(rf_fit, new_data = test_data)) |&gt;\n  bind_cols(test_data |&gt; select(win_red))\n\n# Accuracy, ROC AUC, etc.\nrf_preds |&gt; metrics(truth = win_red, estimate = .pred_class)\n\n# A tibble: 2 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.668\n2 kap      binary         0.318\n\nrf_preds |&gt; roc_auc(truth = win_red, .pred_Red)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.262\n\nrf_preds |&gt; conf_mat(truth = win_red, estimate = .pred_class)\n\n          Truth\nPrediction Blue Red\n      Blue  220 126\n      Red   166 368\n\n\nIn this section, I built and evaluated two classification models to predict whether the Red corner fighter wins a given UFC fight, using fight-level differences in physical attributes and performance metrics. The models I chose are logistic regression and random forest—two commonly used methods for classification problems with different strengths.\nModel 1: Logistic Regression Logistic regression is a linear model that estimates the probability of a binary outcome—in this case, whether the Red fighter wins (1) or not (0). It models the log-odds of the outcome as a linear combination of the predictors. This method is straightforward, interpretable, and serves as a strong baseline.\nModel 2: Random Forest Random forest is an ensemble model that builds many decision trees and combines them by averaging (for regression) or voting (for classification). It’s good at capturing nonlinear relationships and interactions automatically. I used the ranger engine to fit the model efficiently with 500 trees, using 3 variables at each split (mtry = 3).\nBoth models used the same set of predictors, selected from earlier EDA: - age_diff - reach_diff - td_diff (takedown attempts difference) - ctrl_sec_diff (control time difference) - sig_str_acc_total_diff (significant strike accuracy difference over career)\nAll numeric predictors were normalized using step_normalize() in a recipe() to ensure fair scaling, especially for logistic regression.\nAfter fitting each model, I predicted outcomes on the test set and evaluated the models using three standard classification metrics: accuracy, ROC AUC, and the confusion matrix. Accuracy measures the overall percentage of correct predictions. ROC AUC (Area Under the Receiver Operating Characteristic Curve) evaluates how well the model separates positive from negative cases, regardless of the chosen cutoff. Confusion Matrix breaks down the performance into True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN), which helps understand what kind of mistakes the model makes.\nBoth models performed similarly, with logistic regression having a slight edge in raw accuracy and the random forest showing slightly more discrimination (AUC). However, both models struggled to confidently separate winners from losers based on the variables provided. Future improvements could involve feature engineering (e.g., removing in-fight variables like ctrl_sec_diff to avoid data leakage), including historical performance trends, and possibly tuning or ensembling models. ## Insights\n\nrf_fit %&gt;%\n  extract_fit_parsnip() %&gt;%\n  vip::vip(num_features = 10)\n\n\n\n\n\n\n\n\nThe primary finding from this project is that while some fighter-level differences (such as reach and age) show moderate patterns with fight outcomes, they alone are not strong predictors of who wins a UFC fight. My models logistic regression and random forest — achieved around 67–69% accuracy, which is slightly better than guessing but not strong enough for high-stakes prediction or decision-making.\nOne of the clearest patterns observed during exploratory analysis was that fighters with longer reach and better historical strike accuracy were slightly more likely to win, especially in certain weight classes. This was visualized through boxplots and density plots where red fighters had higher values in reach_diff and sig_str_acc_total_diff more often when they won.\nHowever, the models’ low ROC AUC scores (around 0.24–0.26) suggest that the predictive signal from these variables is weak when applied to new data. This implies that either (1) the features used do not capture the full complexity of UFC outcomes, or (2) there may be a lot of randomness or hidden contextual factors (like strategy, corner advice, injuries, or judging biases) that aren’t captured in the stats alone. Also when it came to random forest tree, the difference that came out important was the control variable; this suggests that winning a fight may be more closely tied to a fighter’s ability to control their opponent.\nDespite the weak prediction performance, this project shows that modeling fight outcomes is feasible with public stats, and that certain differences (like control time, takedowns, and reach) do relate to success — just not strongly enough in isolation to make reliable predictions.\n\nLimitations and Future Work\n\n\nReflection (Optional Subsection)"
  }
]